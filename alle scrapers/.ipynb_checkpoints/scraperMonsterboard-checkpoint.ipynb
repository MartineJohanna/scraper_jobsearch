{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1a635d6c44a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re, html\n",
    "import bs4\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functies voor de scraper\n",
    "def get_soup(text):\n",
    "    return BeautifulSoup(text, \"lxml\", from_encoding=\"utf-8\")\n",
    "\n",
    "#zoek titel functie\n",
    "def zoek_titel(divs):\n",
    "    titel = div.find(\"h2\",attrs={\"class\":\"title\"})\n",
    "    if titel is not None:\n",
    "        return titel.get_text()\n",
    "    \n",
    "#zoek link naar vacature\n",
    "def zoek_link(divs):\n",
    "    aa = div.find(\"a\",attrs={\"data-bypass\":True})\n",
    "    if aa is not None:\n",
    "        return aa['href']\n",
    "\n",
    "# zoek naam van bedrijf\n",
    "def zoek_bedrijf(divs):\n",
    "    comp = div.find(\"a\",attrs={\"class\":\"name\"})\n",
    "    if comp is not None:\n",
    "        return comp.get_text()\n",
    "\n",
    "# zoek locatie functie\n",
    "def zoek_locatie(divs):\n",
    "    locatie = div.find(attrs={\"class\":\"location\"})\n",
    "    if locatie is not None:\n",
    "        return locatie.get_text()\n",
    "\n",
    "#zoek hele vacature    \n",
    "def hele_vac(soup):\n",
    "    vac = soup.find(attrs={'class':'job-description'})\n",
    "    if vac is not None:\n",
    "        return vac.get_text()\n",
    "    \n",
    "def laad_vac(soup):\n",
    "    laad = soup.find(attrs={'id':'loadMoreJobs'})\n",
    "    return laad.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartineWester\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:185: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "# scrapen van elke pagina op zoekterm data \n",
    "for i in range(1,1000):    \n",
    "    \n",
    "    titel=[]\n",
    "    bedrijf=[]\n",
    "    plaats=[]\n",
    "    link=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    page = requests.get('https://www.monsterboard.nl/vacatures/zoeken/?q=data&where=nederland&cy=nl&stpage=1&page=' + str(i))\n",
    "    soup = get_soup(page.text)\n",
    "    divs = soup.findAll(\"div\",attrs={\"class\":\"flex-row\"})\n",
    "    \n",
    "    if(len(divs) == 0):\n",
    "        break\n",
    "    \n",
    "    for div in divs:\n",
    "        titel.append(zoek_titel(div))\n",
    "        bedrijf.append(zoek_bedrijf(div))\n",
    "        plaats.append(zoek_locatie(div))\n",
    "        link.append(zoek_link(div)) \n",
    "        \n",
    "        if 'data' not in zoek_titel(div).lower():\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe van de resultaten\n",
    "df = pd.DataFrame(\n",
    "    {'titel': titel,\n",
    "     'bedrijf': bedrijf,\n",
    "     'plaats': plaats,\n",
    "     'link': link\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapen van de inhoud voor elke vacature\n",
    "df2 = pd.DataFrame([])\n",
    "vacs = []\n",
    "cnt = 0\n",
    "for _, vac in df.iterrows():   \n",
    "\n",
    "    alles = []\n",
    "    if vac['link'] is not None:\n",
    "        xrnd = np.random.uniform(3, 6)\n",
    "        time.sleep(xrnd)\n",
    "        num = (cnt + 1)     \n",
    "        cnt = cnt + 1\n",
    "        \n",
    "        \n",
    "        original_url = vac['link']\n",
    "        job_id = original_url.split('/')[-1]\n",
    "        url = f'https://services.monster.io/jobs-svx-service/v1/jobs/{job_id}'\n",
    "        r = requests.get(url)\n",
    "        json_body = r.json()\n",
    "        alles.append(json_body)\n",
    "        df2[num] = alles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joinen van de dataframes \n",
    "df2 = df2.T\n",
    "df2.rename(columns={df2.columns[0]: \"alles\"}, inplace=True)\n",
    "result = df.merge(df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe opslaan\n",
    "result.to_csv('monsterboard_nederland.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
