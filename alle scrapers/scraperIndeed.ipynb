{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests\n",
    "import pandas as pd                  \n",
    "import numpy as np\n",
    "import time \n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re, html\n",
    "import bs4\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functies voor de scraper\n",
    "def get_soup(text):\n",
    "    return BeautifulSoup(text, \"lxml\", from_encoding=\"utf-8\")\n",
    "\n",
    "# titel van de functie\n",
    "def zoek_titel(div):\n",
    "    titel = div.find(attrs={'class':'title'})\n",
    "    if titel is not None:\n",
    "        return titel.get_text()\n",
    "\n",
    "# bedrijf van de vacature    \n",
    "def zoek_bedrijf(div):\n",
    "    bedrijf = div.find('span', attrs={'class':'company'})\n",
    "    if bedrijf is not None:\n",
    "        return bedrijf.get_text()\n",
    "    else: \n",
    "        sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "        return sec_try.get_text()\n",
    "\n",
    "# locatie van de vacature\n",
    "def zoek_locatie(div):\n",
    "    locatie = div.find(attrs={'class':'location accessible-contrast-color-location'})\n",
    "    if locatie is not None:\n",
    "        return locatie.get_text()\n",
    "\n",
    "# link naar de vacature\n",
    "def zoek_link(div):\n",
    "    for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "        return a['href']\n",
    "\n",
    "# text van de vacature \n",
    "def zoek_alles(html):\n",
    "    spans = soup.findAll('div', attrs={'class': \"jobsearch-jobDescriptionText\"})\n",
    "    for span in spans:\n",
    "        return span.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartineWester\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:185: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "titel=[]\n",
    "bedrijf=[]\n",
    "plaats=[]\n",
    "link=[]\n",
    "\n",
    "# scrapen van elke pagina op zoekterm data engineering\n",
    "for i in range(1, 1000):\n",
    "    xrnd = np.random.uniform(3, 6)\n",
    "    time.sleep(xrnd)\n",
    "\n",
    "    page = requests.get('https://www.indeed.nl/jobs?q=data+engineer&l=nederland&start='+ str(i))\n",
    "    soup = get_soup(page.text)\n",
    "    divs = soup.find_all(name=\"div\", attrs={\"class\":\"row\"})\n",
    "    \n",
    "    if(len(divs) == 0):\n",
    "        break\n",
    "\n",
    "    for div in divs:\n",
    "        \n",
    "        titel.append(zoek_titel(div))\n",
    "        bedrijf.append(zoek_bedrijf(div))\n",
    "        plaats.append(zoek_locatie(div))\n",
    "        link.append(zoek_link(div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe van de resultaten\n",
    "df = pd.DataFrame(\n",
    "    {'titel': titel,\n",
    "     'bedrijf': bedrijf,\n",
    "     'plaats': plaats,\n",
    "     'link': link\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verwijderen van duplicates\n",
    "df = df.drop_duplicates(subset='link', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapen van de inhoud voor elke vacature\n",
    "df2 = pd.DataFrame([])\n",
    "cnt = -1\n",
    "for _, vac in df.iterrows():   \n",
    "    xrnd = np.random.uniform(3, 4)\n",
    "    time.sleep(xrnd)\n",
    "    \n",
    "    num = (cnt + 1) \n",
    "    \n",
    "    cnt = cnt + 1\n",
    "#     if cnt > 10:\n",
    "#         break;\n",
    "        \n",
    "    page = requests.get('http://www.indeed.nl/' + vac['link'])\n",
    "    soup = get_soup(page.text)\n",
    "    alles = []\n",
    "    \n",
    "    alles.append(zoek_alles(soup))\n",
    "    df2[num] = alles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joinen van de dataframes \n",
    "df2 = df2.T\n",
    "df2.rename(columns={df2.columns[0]: \"alles\"}, inplace=True)\n",
    "result = df.merge(df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe opslaan\n",
    "result.to_csv('indeed_nederland_engineering.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
